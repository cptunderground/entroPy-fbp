\chapter{Evaluation}
Evaluating a system, which takes baby steps into a completely new environement, was quiet challenging. Since most of the work was to come up with the concepts and architecture, the implementation is a little bit chaotic and often not exactly as the given concepts. Nevertheless, the code has been tested and important conclusions were drawn.
\section{Testing Environment}
As seen in the implementation part, the client can call services via requests from the ISP as well as from the server after introducing itself to it. Given this, the main testing aspect was to see that ISP and servers can keep up with the work load and distribute the results back to its origin. The test was as followed:\\
First there were three nodes involved, one client, one ISP and one server. After initialising all nodes the client went into a loop, where it first introduced itself to the server. The server automatically accepted this request and the feed-pair was created. After this, a random number was created between 5 and 20, which were the amount of service requests sent to this now connected server. To mimic a human interaction at first delays between the 1.0 and 4.0 seconds, randomly distributed with one decimal place, were implemented. This was the basic evaluation on functionality, performance, reliability and correctness.

Unfortunately after about 50 requests, either ISP or the server had an exception on the cbor2 library. Something with the bytestream seemed to be broken. Any other solution than just ignoring this exception and leave this specific log entry hanging could not be found. This resulted in open, unresolved request which the client waited for.

In a next step, after ignoring inconsitencies in the log entries, the system was tested to its limits, by having delays lowest at 0.1, adding more clients and up to a thousand iterations per client. Where at the last test with a delay of 0.1 seconds, 5 clients and a combined thousand requests per client, my personal machine nearly broke down. The tests lead to interesting results.

\section{Results}
\subsection{Functionality}
The functionallity was tested manually on different linux distributions\footnote{Ubuntu}\footnote{Arch} where as on Windwos and Mac OS heavy problems occured. The filesystem poller could not detect any changes on feeds, even they were made. As far as concerned and tested on linux distributions the functionallity is complete, the whole process of requesting services from the ISP as well as introducing to diffrent servers is given and works as intended. But only if the user follows strictly through the documentation how the system must be used. The user experiance is rather not intuitive and false use can lead the system to corrupt. This is founded in the very early stage of the project, by iterating over it these issues can be found and eliminated.
\subsection{Performance}
The performance begins with an astonishing speed and collapses over time. This fact was already know at the implementation point. To distinguish already handled and completed requests, the systen cycles through the whole feed, every time a change is detected. This problem can be solved by indexing the feed and saving the position, where everything already has been done. This factor has been left out intentionally to concentrate on the underlying concepts and architecture in the big picture.
\subsection{Reliability and Correctness}
As already teased in the section Testing Environement, some \textit{undefined} or \textit{undiscovered} fault between this implementation and the cbor2 library caused to ignore requests. Having this information, the tradeoff between the reliability and correctness of the feed bundle protocol lay on the hand. Having the underlaying simplified RPC protocol, the fact that request do not get a response violates the consensus if it is not exactly specified. All these findings generalise one big problem. 

\subsection{General Colaboration of Components}
Again having this completle new technology, developed in just a few months, having the main focus on the general aspects results in a patchwork of diffrent libraries, common technologies and new technologies which are not coordinated on each other. To generally improve the very broadly open architecture and concepts need to be thighted with more rules and less freedom resulting in a more specific implementation where the components optimally are written to function well with each other.